{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "House-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMtdbGkhZnLcTCmYZ7u19k3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ronak1998/Raspberrypi/blob/master/House_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOG1q1jIENSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# univariate cnn lstm example\n",
        "import tensorflow.compat.v1 as tf\n",
        "from numpy import array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "import keras.utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEIMR3yBEQbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "from datetime import date, time, timedelta\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "from numpy import save\n",
        "from sklearn import preprocessing\n",
        "from google.colab import drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDeCPgBbET6X",
        "colab_type": "code",
        "outputId": "0fc66210-51a3-4f7f-b011-c79a9e8f6dd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56e0h1vhEWRy",
        "colab_type": "code",
        "outputId": "8cad4fe6-32b8-4236-f607-6083c938a3d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "file = r'/gdrive/My Drive/Colab Notebooks/NILM/REDDhouse1_lowf_VA.csv'\n",
        "df = pd.read_csv(file)\n",
        "print(df)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        TimeStamp    MAIN   OVEN   REFG  ...   BATH   HEAT   STOV   DIFF\n",
            "0       1303132933    340      0      6  ...      1      0      0     79\n",
            "1       1303132936    342      0      6  ...      1      0      0     81\n",
            "2       1303132940    341      0      6  ...      1      0      0     79\n",
            "3       1303132943    341      0      6  ...      1      0      0     79\n",
            "4       1303132946    340      0      6  ...      1      0      0     79\n",
            "...            ...    ...    ...    ...  ...    ...    ...    ...    ...\n",
            "406743  1306266980    273      0    186  ...      1      0      0     31\n",
            "406744  1306266983    273      0    187  ...      1      0      0     33\n",
            "406745  1306266987    273      0    190  ...      1      0      0     30\n",
            "406746  1306266990    273      0    189  ...      1      0      0     31\n",
            "406747  1306266994    273      0    186  ...      1      0      0     32\n",
            "\n",
            "[406748 rows x 13 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeVhrK0tEguH",
        "colab_type": "code",
        "outputId": "f8c1726e-2878-4456-e5ae-7ad68c1d5a8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "array = df.to_numpy()\n",
        "dataset = pd.DataFrame({'timestamp': array[:,0], 'Main': array[:,1], 'Oven': array[:,2], 'Refg': array[:,3], 'Dish': array[:,4], 'Kitch': array[:,5], 'Lite': array[:,6], 'Dryr': array[:,7], 'Micr': array[:,8], 'Bath': array[:,9], 'Heat': array[:,10], 'Stov': array[:,11],'Diff': array[:,12]})\n",
        "dataset = dataset.set_index(['timestamp'])\n",
        "dataset.index = pd.to_datetime(dataset.index, unit='s')\n",
        "dataset = dataset.resample('1min').mean()\n",
        "dataset = dataset.dropna()\n",
        "dataset.describe()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Main</th>\n",
              "      <th>Oven</th>\n",
              "      <th>Refg</th>\n",
              "      <th>Dish</th>\n",
              "      <th>Kitch</th>\n",
              "      <th>Lite</th>\n",
              "      <th>Dryr</th>\n",
              "      <th>Micr</th>\n",
              "      <th>Bath</th>\n",
              "      <th>Heat</th>\n",
              "      <th>Stov</th>\n",
              "      <th>Diff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>26297.000000</td>\n",
              "      <td>26297.000000</td>\n",
              "      <td>26297.000000</td>\n",
              "      <td>26297.000000</td>\n",
              "      <td>26297.000000</td>\n",
              "      <td>26297.000000</td>\n",
              "      <td>26297.000000</td>\n",
              "      <td>26297.000000</td>\n",
              "      <td>26297.000000</td>\n",
              "      <td>26297.000000</td>\n",
              "      <td>26297.000000</td>\n",
              "      <td>26297.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>382.908284</td>\n",
              "      <td>13.731572</td>\n",
              "      <td>54.990180</td>\n",
              "      <td>25.396969</td>\n",
              "      <td>57.172662</td>\n",
              "      <td>74.117537</td>\n",
              "      <td>35.850292</td>\n",
              "      <td>22.183838</td>\n",
              "      <td>7.003494</td>\n",
              "      <td>0.127257</td>\n",
              "      <td>0.114912</td>\n",
              "      <td>92.219572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>747.425265</td>\n",
              "      <td>211.077353</td>\n",
              "      <td>85.166772</td>\n",
              "      <td>149.214637</td>\n",
              "      <td>87.244082</td>\n",
              "      <td>64.251739</td>\n",
              "      <td>288.437464</td>\n",
              "      <td>147.068870</td>\n",
              "      <td>91.989994</td>\n",
              "      <td>0.946020</td>\n",
              "      <td>0.799245</td>\n",
              "      <td>334.331542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>90.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.266667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.687500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>136.875000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.312500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>43.125000</td>\n",
              "      <td>3.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>32.687500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>175.812500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>81.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>37.375000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>349.312500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>101.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>46.000000</td>\n",
              "      <td>84.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>11556.250000</td>\n",
              "      <td>4156.625000</td>\n",
              "      <td>437.800000</td>\n",
              "      <td>1153.066667</td>\n",
              "      <td>2725.600000</td>\n",
              "      <td>418.666667</td>\n",
              "      <td>3251.812500</td>\n",
              "      <td>1771.250000</td>\n",
              "      <td>1664.187500</td>\n",
              "      <td>19.600000</td>\n",
              "      <td>16.333333</td>\n",
              "      <td>3378.937500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Main          Oven  ...          Stov          Diff\n",
              "count  26297.000000  26297.000000  ...  26297.000000  26297.000000\n",
              "mean     382.908284     13.731572  ...      0.114912     92.219572\n",
              "std      747.425265    211.077353  ...      0.799245    334.331542\n",
              "min       90.666667      0.000000  ...      0.000000      0.800000\n",
              "25%      136.875000      0.000000  ...      0.000000     32.687500\n",
              "50%      175.812500      0.000000  ...      0.000000     37.375000\n",
              "75%      349.312500      0.000000  ...      0.000000     54.000000\n",
              "max    11556.250000   4156.625000  ...     16.333333   3378.937500\n",
              "\n",
              "[8 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RekQKr5uQwt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8flyydDIEjnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LSTM_pre_processing(dataset, appliance, starting, ending, value1, value2):\n",
        "  for i in range(starting, ending):\n",
        "    if value1 == 0:\n",
        "      if dataset[appliance][i] > value2:\n",
        "        dataset[\"Lite\"][i] = 1\n",
        "      else:\n",
        "        dataset[\"Lite\"][i] = 0\n",
        "\n",
        "    else:\n",
        "      if dataset[appliance][i] > value1:\n",
        "        if dataset[appliance][i] < value2:\n",
        "          dataset[\"Lite\"][i] = 1\n",
        "        else:\n",
        "          dataset[\"Lite\"][i] = 0\n",
        "      else:\n",
        "        dataset[\"Lite\"][i] = 0\n",
        "\n",
        "\n",
        "  flag = 0\n",
        "  for i in range(starting+1,ending):\n",
        "    if dataset[\"Lite\"][i] == 1:\n",
        "      if dataset[\"Lite\"][i-1] == 1:\n",
        "        flag+=1\n",
        "      else:\n",
        "        flag = 1\n",
        "    else:\n",
        "      flag = 0\n",
        "    dataset[\"Kitch\"][i] = flag\n",
        "\n",
        "  continues_active_sequence = []\n",
        "  temp = []\n",
        "  for i in range(starting, ending):\n",
        "    if dataset[\"Kitch\"][i] > 0:\n",
        "      temp1 = []\n",
        "      temp1.append(dataset[\"Kitch\"][i])\n",
        "      temp1.append(dataset[appliance][i])\n",
        "      temp.append(temp1)\n",
        "    else:\n",
        "      if len(temp) > 0:\n",
        "        continues_active_sequence.append(temp)\n",
        "        temp = []\n",
        "\n",
        "\n",
        "  train_x = []\n",
        "  train_y = []\n",
        "  for i in range(1,len(continues_active_sequence)):\n",
        "    temp1 = [0,0,0,0,0]\n",
        "    train_x.append(temp1)\n",
        "    norm = (continues_active_sequence[i][0][1])\n",
        "    train_y.append(norm)\n",
        "    temp1 = [0,0,0,0]\n",
        "    for j in range(0,len(continues_active_sequence[i])-1):\n",
        "      norm1 = (continues_active_sequence[i][j][0])\n",
        "      temp1.append(norm1)\n",
        "      train_x.append(temp1)\n",
        "      norm2 = (continues_active_sequence[i][j+1][1])\n",
        "      train_y.append(norm2)\n",
        "      temp3 = []\n",
        "      for k in range(1,len(temp1)):\n",
        "        temp3.append(temp1[k])\n",
        "      temp1 = temp3\n",
        "\n",
        "  LSTM_X = np.asarray(train_x)\n",
        "  LSTM_y = np.asarray(train_y)\n",
        "\n",
        "  return LSTM_X, LSTM_y;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1MBRZ2aIoZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CNN_pre_processing (dataset, appliance, starting, ending, value1, value2):\n",
        "  for i in range(starting, ending):\n",
        "    if value1 == 0:\n",
        "      if dataset[appliance][i] > value2:\n",
        "        dataset[\"Lite\"][i] = 1\n",
        "      else:\n",
        "        dataset[\"Lite\"][i] = 0\n",
        "\n",
        "    else:\n",
        "      if dataset[appliance][i] > value1:\n",
        "        if dataset[appliance][i] < value2:\n",
        "          dataset[\"Lite\"][i] = 1\n",
        "        else:\n",
        "          dataset[\"Lite\"][i] = 0\n",
        "      else:\n",
        "        dataset[\"Lite\"][i] = 0\n",
        "\n",
        "  x = dataset.values #returns a numpy array\n",
        "  min_max_scaler = preprocessing.MinMaxScaler()\n",
        "  x_scaled = min_max_scaler.fit_transform(x)\n",
        "  dataset1 = pd.DataFrame(x_scaled)\n",
        "\n",
        "\n",
        "  lite = (dataset.index[starting+1] - dataset.index[starting])\n",
        "  lite = str(lite)\n",
        "  main_array = []\n",
        "  check = lite\n",
        "\n",
        "  temp = []\n",
        "  for i in range(starting+1,ending):\n",
        "      difference = dataset.index[i] - dataset.index[i-1]\n",
        "      string = str(difference)\n",
        "      if string == check:\n",
        "          temp1 = []\n",
        "          temp2 = []\n",
        "          temp1.append(dataset1[0][i])\n",
        "          temp1.append(dataset[\"Lite\"][i])\n",
        "          temp.append(temp1)\n",
        "      else:\n",
        "          main_array.append(temp)\n",
        "          temp = []\n",
        "\n",
        "\n",
        "\n",
        "  final_array = []\n",
        "  for i in range(0,len(main_array)):\n",
        "      length = len(main_array[i])\n",
        "      modu = length%20\n",
        "      if modu < 10:\n",
        "          temp = []\n",
        "          for j in range(0,len(main_array[i])-modu):\n",
        "              temp.append(main_array[i][j])\n",
        "          final_array.append(temp)\n",
        "      else:\n",
        "          temp = main_array[i]\n",
        "          for j in range(0,20 - modu):\n",
        "              array = [0,0]\n",
        "              temp.append(array)\n",
        "          final_array.append(temp)\n",
        "\n",
        "  test_array = []\n",
        "  for i in range(0,len(final_array)):\n",
        "      temp = []\n",
        "      for j in range(0,10):\n",
        "          temp.append([0,0])\n",
        "      for j in range(0,len(final_array[i])):\n",
        "          temp.append(final_array[i][j])\n",
        "      for j in range(0,10):\n",
        "          temp.append([0,0])\n",
        "      test_array.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "  training_set = []\n",
        "  for i in range(0,len(test_array)):\n",
        "      for j in range(0,len(test_array[i])-20):\n",
        "          x_y = []\n",
        "          temp = []\n",
        "          for k in range(j,j+20):\n",
        "              temp.append(test_array[i][k][0])\n",
        "          x_y.append(temp)\n",
        "          x_y.append(test_array[i][j+10][1])\n",
        "          training_set.append(x_y)\n",
        "\n",
        "\n",
        "  X = []\n",
        "  y = []\n",
        "  for i in range(0,len(training_set)):\n",
        "    lets = training_set[i][0]\n",
        "    lets = np.asarray(lets)\n",
        "    X.append(lets)\n",
        "    y.append(training_set[i][1])\n",
        "\n",
        "\n",
        "  X = np.asarray(X)\n",
        "  y = np.asarray(y)\n",
        "  from keras.utils import to_categorical\n",
        "  y = to_categorical(y)\n",
        "\n",
        "\n",
        "\n",
        "  return X,y;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EafAWHvkGWid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LSTM_X_refg,LSTM_y_refg = LSTM_pre_processing(dataset, \"Refg\", 0,  (len(dataset.index)-8000), 0, 100)\n",
        "\n",
        "LSTM_X_micr,LSTM_y_micr = LSTM_pre_processing(dataset, \"Micr\", 0,  (len(dataset.index)-8000), 0, 600)\n",
        "\n",
        "LSTM_X_dish1,LSTM_y_dish1 = LSTM_pre_processing(dataset, \"Dish\", 0,  (len(dataset.index)-8000), 100, 500)\n",
        "\n",
        "LSTM_X_dish2,LSTM_y_dish2 = LSTM_pre_processing(dataset, \"Dish\", 0,  (len(dataset.index)-8000), 0, 850)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHnXr8QpG_tO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_refg, y_refg = CNN_pre_processing(dataset, \"Refg\", 0, (len(dataset.index)-8000), 0, 100)\n",
        "\n",
        "X_micr, y_micr = CNN_pre_processing(dataset, \"Micr\", 0, (len(dataset.index)-8000), 0, 600)\n",
        "\n",
        "X_dish1, y_dish1 = CNN_pre_processing(dataset, \"Dish\", 0, (len(dataset.index)-8000), 100, 600)\n",
        "\n",
        "X_dish2, y_dish2 = CNN_pre_processing(dataset, \"Dish\", 0, (len(dataset.index)-8000), 0, 850)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxGacxQoMYE9",
        "colab_type": "code",
        "outputId": "cf4f2e92-db5c-4ff6-a435-bf6184a8934e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(X_dish1), len(LSTM_X_dish1))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17740 357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I05H7hW2csqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Bidirectional"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2WCa32InKS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_features = 1\n",
        "#n_seq = 2\n",
        "n_steps = 20\n",
        "X_refg = X_refg.reshape((X_refg.shape[0], n_steps, n_features))\n",
        "\n",
        "X_micr = X_micr.reshape((X_micr.shape[0], n_steps, n_features))\n",
        "\n",
        "X_dish1 = X_dish1.reshape((X_dish1.shape[0], n_steps, n_features))\n",
        "\n",
        "X_dish2 = X_dish2.reshape((X_dish2.shape[0], n_steps, n_features))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zlk_PDJjahkI",
        "colab_type": "code",
        "outputId": "b4267914-1b93-4eb3-c52e-81e6d5d8af0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "model_dish1 = Sequential()\n",
        "model_dish1.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_steps,n_features)))\n",
        "model_dish1.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model_dish1.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "#model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "#model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "#model.add(Dropout(0.5))\n",
        "model_dish1.add(MaxPooling1D(pool_size=2))\n",
        "model_dish1.add(Flatten())\n",
        "model_dish1.add(Dense(100, activation='relu'))\n",
        "model_dish1.add(Dense(2, activation='softmax'))\n",
        "model_dish1.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "model_dish1.fit(X_dish1, y_dish1, epochs=20, validation_split=0.1, verbose=1)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15966 samples, validate on 1774 samples\n",
            "Epoch 1/20\n",
            "15966/15966 [==============================] - 3s 211us/step - loss: 0.1065 - accuracy: 0.9771 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "15966/15966 [==============================] - 3s 193us/step - loss: 0.0742 - accuracy: 0.9770 - val_loss: 0.0253 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "15966/15966 [==============================] - 3s 196us/step - loss: 0.0684 - accuracy: 0.9773 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "15966/15966 [==============================] - 3s 199us/step - loss: 0.0640 - accuracy: 0.9791 - val_loss: 0.0067 - val_accuracy: 0.9983\n",
            "Epoch 5/20\n",
            "15966/15966 [==============================] - 3s 196us/step - loss: 0.0607 - accuracy: 0.9798 - val_loss: 0.0123 - val_accuracy: 0.9972\n",
            "Epoch 6/20\n",
            "15966/15966 [==============================] - 3s 197us/step - loss: 0.0591 - accuracy: 0.9806 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "15966/15966 [==============================] - 3s 199us/step - loss: 0.0554 - accuracy: 0.9818 - val_loss: 0.0127 - val_accuracy: 0.9994\n",
            "Epoch 8/20\n",
            "15966/15966 [==============================] - 3s 193us/step - loss: 0.0497 - accuracy: 0.9825 - val_loss: 9.9485e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "15966/15966 [==============================] - 3s 196us/step - loss: 0.0506 - accuracy: 0.9821 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "15966/15966 [==============================] - 3s 195us/step - loss: 0.0459 - accuracy: 0.9836 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "15966/15966 [==============================] - 3s 204us/step - loss: 0.0427 - accuracy: 0.9842 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "15966/15966 [==============================] - 3s 195us/step - loss: 0.0388 - accuracy: 0.9855 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "15966/15966 [==============================] - 3s 199us/step - loss: 0.0358 - accuracy: 0.9876 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "15966/15966 [==============================] - 3s 197us/step - loss: 0.0348 - accuracy: 0.9887 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "15966/15966 [==============================] - 3s 196us/step - loss: 0.0321 - accuracy: 0.9886 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "15966/15966 [==============================] - 3s 198us/step - loss: 0.0279 - accuracy: 0.9908 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "15966/15966 [==============================] - 3s 200us/step - loss: 0.0264 - accuracy: 0.9914 - val_loss: 0.0016 - val_accuracy: 0.9994\n",
            "Epoch 18/20\n",
            "15966/15966 [==============================] - 3s 196us/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "15966/15966 [==============================] - 3s 199us/step - loss: 0.0202 - accuracy: 0.9934 - val_loss: 0.0073 - val_accuracy: 0.9989\n",
            "Epoch 20/20\n",
            "15966/15966 [==============================] - 3s 198us/step - loss: 0.0186 - accuracy: 0.9935 - val_loss: 9.5513e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f867fa7ef60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1STtw-qahCL",
        "colab_type": "code",
        "outputId": "066311db-7dc3-4477-bfea-2216e6d9ce0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "model_dish2 = Sequential()\n",
        "model_dish2.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_steps,n_features)))\n",
        "model_dish2.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model_dish2.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "#model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "#model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "#model.add(Dropout(0.5))\n",
        "model_dish2.add(MaxPooling1D(pool_size=2))\n",
        "model_dish2.add(Flatten())\n",
        "model_dish2.add(Dense(100, activation='relu'))\n",
        "model_dish2.add(Dense(2, activation='softmax'))\n",
        "model_dish2.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "model_dish2.fit(X_dish2, y_dish2, epochs=20, validation_split=0.1, verbose=1)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15966 samples, validate on 1774 samples\n",
            "Epoch 1/20\n",
            "15966/15966 [==============================] - 4s 226us/step - loss: 0.0438 - accuracy: 0.9903 - val_loss: 3.5557e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "15966/15966 [==============================] - 3s 207us/step - loss: 0.0093 - accuracy: 0.9966 - val_loss: 1.5191e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "15966/15966 [==============================] - 3s 194us/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 3.3694e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "15966/15966 [==============================] - 3s 195us/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 2.4289e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "15966/15966 [==============================] - 3s 198us/step - loss: 0.0068 - accuracy: 0.9977 - val_loss: 8.5822e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "15966/15966 [==============================] - 3s 196us/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "15966/15966 [==============================] - 3s 200us/step - loss: 0.0059 - accuracy: 0.9977 - val_loss: 7.9356e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "15966/15966 [==============================] - 3s 198us/step - loss: 0.0067 - accuracy: 0.9975 - val_loss: 1.3917e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "15966/15966 [==============================] - 3s 203us/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "15966/15966 [==============================] - 3s 208us/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 2.4165e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "15966/15966 [==============================] - 3s 205us/step - loss: 0.0052 - accuracy: 0.9982 - val_loss: 1.7886e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "15966/15966 [==============================] - 3s 200us/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 9.3484e-05 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "15966/15966 [==============================] - 3s 204us/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 1.7618e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "15966/15966 [==============================] - 3s 205us/step - loss: 0.0065 - accuracy: 0.9977 - val_loss: 1.2126e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "15966/15966 [==============================] - 3s 206us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 1.4251e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "15966/15966 [==============================] - 3s 207us/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 1.3658e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "15966/15966 [==============================] - 3s 205us/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 4.3225e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "15966/15966 [==============================] - 3s 209us/step - loss: 0.0042 - accuracy: 0.9986 - val_loss: 4.0129e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "15966/15966 [==============================] - 3s 207us/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 1.1293e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "15966/15966 [==============================] - 3s 203us/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 2.9665e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f867efdc898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEnK3VUuPPEr",
        "colab_type": "code",
        "outputId": "51bec1c6-fca3-4fb3-d762-029669463afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "model_micr = Sequential()\n",
        "model_micr.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_steps,n_features)))\n",
        "model_micr.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model_micr.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "#model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "#model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "#model.add(Dropout(0.5))\n",
        "model_micr.add(MaxPooling1D(pool_size=2))\n",
        "model_micr.add(Flatten())\n",
        "model_micr.add(Dense(100, activation='relu'))\n",
        "model_micr.add(Dense(2, activation='softmax'))\n",
        "model_micr.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "model_micr.fit(X_micr, y_micr, epochs=20, validation_split=0.1, verbose=1)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15966 samples, validate on 1774 samples\n",
            "Epoch 1/20\n",
            "15966/15966 [==============================] - 3s 215us/step - loss: 0.0748 - accuracy: 0.9820 - val_loss: 0.0301 - val_accuracy: 0.9927\n",
            "Epoch 2/20\n",
            "15966/15966 [==============================] - 3s 199us/step - loss: 0.0404 - accuracy: 0.9844 - val_loss: 0.0197 - val_accuracy: 0.9961\n",
            "Epoch 3/20\n",
            "15966/15966 [==============================] - 3s 208us/step - loss: 0.0334 - accuracy: 0.9855 - val_loss: 0.0224 - val_accuracy: 0.9932\n",
            "Epoch 4/20\n",
            "15966/15966 [==============================] - 3s 208us/step - loss: 0.0315 - accuracy: 0.9862 - val_loss: 0.0222 - val_accuracy: 0.9938\n",
            "Epoch 5/20\n",
            "15966/15966 [==============================] - 3s 202us/step - loss: 0.0281 - accuracy: 0.9871 - val_loss: 0.0191 - val_accuracy: 0.9955\n",
            "Epoch 6/20\n",
            "15966/15966 [==============================] - 3s 208us/step - loss: 0.0268 - accuracy: 0.9882 - val_loss: 0.0179 - val_accuracy: 0.9961\n",
            "Epoch 7/20\n",
            "15966/15966 [==============================] - 3s 206us/step - loss: 0.0223 - accuracy: 0.9910 - val_loss: 0.0184 - val_accuracy: 0.9932\n",
            "Epoch 8/20\n",
            "15966/15966 [==============================] - 3s 207us/step - loss: 0.0193 - accuracy: 0.9917 - val_loss: 0.0228 - val_accuracy: 0.9915\n",
            "Epoch 9/20\n",
            "15966/15966 [==============================] - 3s 207us/step - loss: 0.0185 - accuracy: 0.9927 - val_loss: 0.0202 - val_accuracy: 0.9961\n",
            "Epoch 10/20\n",
            "15966/15966 [==============================] - 3s 201us/step - loss: 0.0199 - accuracy: 0.9916 - val_loss: 0.0230 - val_accuracy: 0.9932\n",
            "Epoch 11/20\n",
            "15966/15966 [==============================] - 3s 200us/step - loss: 0.0138 - accuracy: 0.9948 - val_loss: 0.0245 - val_accuracy: 0.9927\n",
            "Epoch 12/20\n",
            "15966/15966 [==============================] - 3s 209us/step - loss: 0.0138 - accuracy: 0.9945 - val_loss: 0.0311 - val_accuracy: 0.9882\n",
            "Epoch 13/20\n",
            "15966/15966 [==============================] - 3s 199us/step - loss: 0.0133 - accuracy: 0.9948 - val_loss: 0.0307 - val_accuracy: 0.9938\n",
            "Epoch 14/20\n",
            "15966/15966 [==============================] - 3s 200us/step - loss: 0.0112 - accuracy: 0.9959 - val_loss: 0.0236 - val_accuracy: 0.9949\n",
            "Epoch 15/20\n",
            "15966/15966 [==============================] - 3s 198us/step - loss: 0.0144 - accuracy: 0.9940 - val_loss: 0.0326 - val_accuracy: 0.9927\n",
            "Epoch 16/20\n",
            "15966/15966 [==============================] - 3s 203us/step - loss: 0.0089 - accuracy: 0.9966 - val_loss: 0.0509 - val_accuracy: 0.9915\n",
            "Epoch 17/20\n",
            "15966/15966 [==============================] - 3s 206us/step - loss: 0.0093 - accuracy: 0.9961 - val_loss: 0.0383 - val_accuracy: 0.9904\n",
            "Epoch 18/20\n",
            "15966/15966 [==============================] - 3s 200us/step - loss: 0.0076 - accuracy: 0.9968 - val_loss: 0.0567 - val_accuracy: 0.9904\n",
            "Epoch 19/20\n",
            "15966/15966 [==============================] - 3s 200us/step - loss: 0.0082 - accuracy: 0.9964 - val_loss: 0.0545 - val_accuracy: 0.9921\n",
            "Epoch 20/20\n",
            "15966/15966 [==============================] - 3s 199us/step - loss: 0.0064 - accuracy: 0.9974 - val_loss: 0.0559 - val_accuracy: 0.9915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f867f690b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5V6hRagS50A",
        "colab_type": "code",
        "outputId": "0227d956-c164-432e-d2dc-5eefe37b5891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "model_refg = Sequential()\n",
        "model_refg.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_steps,n_features)))\n",
        "model_refg.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model_refg.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "#model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "#model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "#model.add(Dropout(0.5))\n",
        "model_refg.add(MaxPooling1D(pool_size=2))\n",
        "model_refg.add(Flatten())\n",
        "model_refg.add(Dense(100, activation='relu'))\n",
        "model_refg.add(Dense(2, activation='softmax'))\n",
        "model_refg.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model_refg.fit(X_refg, y_refg, epochs=20, validation_split=0.1, verbose=1)\n",
        "\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15966 samples, validate on 1774 samples\n",
            "Epoch 1/20\n",
            "15966/15966 [==============================] - 3s 213us/step - loss: 0.3634 - accuracy: 0.8146 - val_loss: 0.1984 - val_accuracy: 0.9092\n",
            "Epoch 2/20\n",
            "15966/15966 [==============================] - 3s 204us/step - loss: 0.2507 - accuracy: 0.8796 - val_loss: 0.2238 - val_accuracy: 0.9014\n",
            "Epoch 3/20\n",
            "15966/15966 [==============================] - 3s 202us/step - loss: 0.2304 - accuracy: 0.8938 - val_loss: 0.1654 - val_accuracy: 0.9177\n",
            "Epoch 4/20\n",
            "15966/15966 [==============================] - 3s 197us/step - loss: 0.2207 - accuracy: 0.8962 - val_loss: 0.1617 - val_accuracy: 0.9273\n",
            "Epoch 5/20\n",
            "15966/15966 [==============================] - 3s 196us/step - loss: 0.2113 - accuracy: 0.9010 - val_loss: 0.1415 - val_accuracy: 0.9363\n",
            "Epoch 6/20\n",
            "15966/15966 [==============================] - 3s 195us/step - loss: 0.2028 - accuracy: 0.9022 - val_loss: 0.1513 - val_accuracy: 0.9391\n",
            "Epoch 7/20\n",
            "15966/15966 [==============================] - 3s 196us/step - loss: 0.1984 - accuracy: 0.9062 - val_loss: 0.1407 - val_accuracy: 0.9431\n",
            "Epoch 8/20\n",
            "15966/15966 [==============================] - 3s 189us/step - loss: 0.1912 - accuracy: 0.9102 - val_loss: 0.1255 - val_accuracy: 0.9538\n",
            "Epoch 9/20\n",
            "15966/15966 [==============================] - 3s 188us/step - loss: 0.1845 - accuracy: 0.9160 - val_loss: 0.1541 - val_accuracy: 0.9425\n",
            "Epoch 10/20\n",
            "15966/15966 [==============================] - 3s 194us/step - loss: 0.1825 - accuracy: 0.9161 - val_loss: 0.1185 - val_accuracy: 0.9498\n",
            "Epoch 11/20\n",
            "15966/15966 [==============================] - 3s 190us/step - loss: 0.1721 - accuracy: 0.9213 - val_loss: 0.1567 - val_accuracy: 0.9543\n",
            "Epoch 12/20\n",
            "15966/15966 [==============================] - 3s 193us/step - loss: 0.1665 - accuracy: 0.9273 - val_loss: 0.1260 - val_accuracy: 0.9515\n",
            "Epoch 13/20\n",
            "15966/15966 [==============================] - 3s 190us/step - loss: 0.1615 - accuracy: 0.9299 - val_loss: 0.1354 - val_accuracy: 0.9414\n",
            "Epoch 14/20\n",
            "15966/15966 [==============================] - 3s 191us/step - loss: 0.1658 - accuracy: 0.9275 - val_loss: 0.1189 - val_accuracy: 0.9431\n",
            "Epoch 15/20\n",
            "15966/15966 [==============================] - 3s 196us/step - loss: 0.1474 - accuracy: 0.9349 - val_loss: 0.1081 - val_accuracy: 0.9521\n",
            "Epoch 16/20\n",
            "15966/15966 [==============================] - 3s 204us/step - loss: 0.1364 - accuracy: 0.9406 - val_loss: 0.1633 - val_accuracy: 0.9318\n",
            "Epoch 17/20\n",
            "15966/15966 [==============================] - 3s 201us/step - loss: 0.1370 - accuracy: 0.9392 - val_loss: 0.1054 - val_accuracy: 0.9577\n",
            "Epoch 18/20\n",
            "15966/15966 [==============================] - 3s 198us/step - loss: 0.1327 - accuracy: 0.9421 - val_loss: 0.1034 - val_accuracy: 0.9600\n",
            "Epoch 19/20\n",
            "15966/15966 [==============================] - 3s 199us/step - loss: 0.1210 - accuracy: 0.9493 - val_loss: 0.1166 - val_accuracy: 0.9510\n",
            "Epoch 20/20\n",
            "15966/15966 [==============================] - 3s 204us/step - loss: 0.1180 - accuracy: 0.9498 - val_loss: 0.1176 - val_accuracy: 0.9549\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f867f3fffd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi4Gia6PTz5c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_steps_lstm = 5\n",
        "n_features_lstm = 1\n",
        "LSTM_X_refg = LSTM_X_refg.reshape((LSTM_X_refg.shape[0], LSTM_X_refg.shape[1], n_features_lstm))\n",
        "\n",
        "LSTM_X_micr = LSTM_X_micr.reshape((LSTM_X_micr.shape[0], LSTM_X_micr.shape[1], n_features_lstm))\n",
        "\n",
        "LSTM_X_dish1 = LSTM_X_dish1.reshape((LSTM_X_dish1.shape[0], LSTM_X_dish1.shape[1], n_features_lstm))\n",
        "\n",
        "LSTM_X_dish2 = LSTM_X_dish2.reshape((LSTM_X_dish2.shape[0], LSTM_X_dish2.shape[1], n_features_lstm))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rQorMoPbX81",
        "colab_type": "code",
        "outputId": "550bfd12-3a9c-4abc-fafc-3a6894f24175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_lstm_dish1 = Sequential()\n",
        "model_lstm_dish1.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps_lstm, n_features_lstm)))\n",
        "model_lstm_dish1.add(LSTM(50, activation='relu'))\n",
        "model_lstm_dish1.add(Dense(1))\n",
        "model_lstm_dish1.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "model_lstm_dish1.fit(LSTM_X_dish1, LSTM_y_dish1, epochs=30, verbose=1)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "357/357 [==============================] - 1s 2ms/step - loss: 72224.5444\n",
            "Epoch 2/30\n",
            "357/357 [==============================] - 0s 218us/step - loss: 71992.0166\n",
            "Epoch 3/30\n",
            "357/357 [==============================] - 0s 221us/step - loss: 70659.0451\n",
            "Epoch 4/30\n",
            "357/357 [==============================] - 0s 230us/step - loss: 63925.9313\n",
            "Epoch 5/30\n",
            "357/357 [==============================] - 0s 222us/step - loss: 58293.8823\n",
            "Epoch 6/30\n",
            "357/357 [==============================] - 0s 244us/step - loss: 55859.2495\n",
            "Epoch 7/30\n",
            "357/357 [==============================] - 0s 215us/step - loss: 52453.2293\n",
            "Epoch 8/30\n",
            "357/357 [==============================] - 0s 220us/step - loss: 46943.9290\n",
            "Epoch 9/30\n",
            "357/357 [==============================] - 0s 241us/step - loss: 39052.7432\n",
            "Epoch 10/30\n",
            "357/357 [==============================] - 0s 224us/step - loss: 27625.8793\n",
            "Epoch 11/30\n",
            "357/357 [==============================] - 0s 221us/step - loss: 14400.5311\n",
            "Epoch 12/30\n",
            "357/357 [==============================] - 0s 220us/step - loss: 8779.4251\n",
            "Epoch 13/30\n",
            "357/357 [==============================] - 0s 220us/step - loss: 9506.8229\n",
            "Epoch 14/30\n",
            "357/357 [==============================] - 0s 226us/step - loss: 9136.4120\n",
            "Epoch 15/30\n",
            "357/357 [==============================] - 0s 224us/step - loss: 9008.1647\n",
            "Epoch 16/30\n",
            "357/357 [==============================] - 0s 231us/step - loss: 9066.3225\n",
            "Epoch 17/30\n",
            "357/357 [==============================] - 0s 231us/step - loss: 9015.6348\n",
            "Epoch 18/30\n",
            "357/357 [==============================] - 0s 235us/step - loss: 9085.4569\n",
            "Epoch 19/30\n",
            "357/357 [==============================] - 0s 224us/step - loss: 9024.7214\n",
            "Epoch 20/30\n",
            "357/357 [==============================] - 0s 229us/step - loss: 8973.3265\n",
            "Epoch 21/30\n",
            "357/357 [==============================] - 0s 250us/step - loss: 9036.3568\n",
            "Epoch 22/30\n",
            "357/357 [==============================] - 0s 234us/step - loss: 8929.5087\n",
            "Epoch 23/30\n",
            "357/357 [==============================] - 0s 233us/step - loss: 9439.1160\n",
            "Epoch 24/30\n",
            "357/357 [==============================] - 0s 232us/step - loss: 8966.2984\n",
            "Epoch 25/30\n",
            "357/357 [==============================] - 0s 222us/step - loss: 9103.1496\n",
            "Epoch 26/30\n",
            "357/357 [==============================] - 0s 225us/step - loss: 8963.8043\n",
            "Epoch 27/30\n",
            "357/357 [==============================] - 0s 232us/step - loss: 9016.2862\n",
            "Epoch 28/30\n",
            "357/357 [==============================] - 0s 230us/step - loss: 9147.8272\n",
            "Epoch 29/30\n",
            "357/357 [==============================] - 0s 233us/step - loss: 9007.2546\n",
            "Epoch 30/30\n",
            "357/357 [==============================] - 0s 230us/step - loss: 8986.2035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f867f016198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeljPfz1bXaN",
        "colab_type": "code",
        "outputId": "42e69772-0d02-489a-d486-c19c67a1debd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_lstm_dish2 = Sequential()\n",
        "model_lstm_dish2.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps_lstm, n_features_lstm)))\n",
        "model_lstm_dish2.add(LSTM(50, activation='relu'))\n",
        "model_lstm_dish2.add(Dense(1))\n",
        "model_lstm_dish2.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "model_lstm_dish2.fit(LSTM_X_dish2, LSTM_y_dish2, epochs=30, verbose=1)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "317/317 [==============================] - 1s 2ms/step - loss: 1215228.4507\n",
            "Epoch 2/30\n",
            "317/317 [==============================] - 0s 225us/step - loss: 1206350.4531\n",
            "Epoch 3/30\n",
            "317/317 [==============================] - 0s 224us/step - loss: 1161196.1408\n",
            "Epoch 4/30\n",
            "317/317 [==============================] - 0s 239us/step - loss: 996442.9509\n",
            "Epoch 5/30\n",
            "317/317 [==============================] - 0s 255us/step - loss: 744306.2946\n",
            "Epoch 6/30\n",
            "317/317 [==============================] - 0s 250us/step - loss: 690677.4789\n",
            "Epoch 7/30\n",
            "317/317 [==============================] - 0s 230us/step - loss: 649261.3214\n",
            "Epoch 8/30\n",
            "317/317 [==============================] - 0s 228us/step - loss: 604774.0743\n",
            "Epoch 9/30\n",
            "317/317 [==============================] - 0s 245us/step - loss: 548794.3616\n",
            "Epoch 10/30\n",
            "317/317 [==============================] - 0s 227us/step - loss: 477436.6438\n",
            "Epoch 11/30\n",
            "317/317 [==============================] - 0s 242us/step - loss: 386654.3752\n",
            "Epoch 12/30\n",
            "317/317 [==============================] - 0s 240us/step - loss: 287049.3865\n",
            "Epoch 13/30\n",
            "317/317 [==============================] - 0s 243us/step - loss: 172171.4820\n",
            "Epoch 14/30\n",
            "317/317 [==============================] - 0s 231us/step - loss: 56887.7117\n",
            "Epoch 15/30\n",
            "317/317 [==============================] - 0s 229us/step - loss: 6677.8409\n",
            "Epoch 16/30\n",
            "317/317 [==============================] - 0s 243us/step - loss: 4693.4485\n",
            "Epoch 17/30\n",
            "317/317 [==============================] - 0s 239us/step - loss: 4249.0463\n",
            "Epoch 18/30\n",
            "317/317 [==============================] - 0s 252us/step - loss: 3575.8791\n",
            "Epoch 19/30\n",
            "317/317 [==============================] - 0s 233us/step - loss: 3183.4956\n",
            "Epoch 20/30\n",
            "317/317 [==============================] - 0s 242us/step - loss: 2969.6796\n",
            "Epoch 21/30\n",
            "317/317 [==============================] - 0s 233us/step - loss: 2907.9011\n",
            "Epoch 22/30\n",
            "317/317 [==============================] - 0s 231us/step - loss: 2880.3962\n",
            "Epoch 23/30\n",
            "317/317 [==============================] - 0s 258us/step - loss: 2872.8024\n",
            "Epoch 24/30\n",
            "317/317 [==============================] - 0s 233us/step - loss: 2718.5745\n",
            "Epoch 25/30\n",
            "317/317 [==============================] - 0s 292us/step - loss: 2680.8280\n",
            "Epoch 26/30\n",
            "317/317 [==============================] - 0s 245us/step - loss: 2762.7165\n",
            "Epoch 27/30\n",
            "317/317 [==============================] - 0s 243us/step - loss: 2721.9392\n",
            "Epoch 28/30\n",
            "317/317 [==============================] - 0s 236us/step - loss: 2622.8600\n",
            "Epoch 29/30\n",
            "317/317 [==============================] - 0s 233us/step - loss: 2609.0182\n",
            "Epoch 30/30\n",
            "317/317 [==============================] - 0s 228us/step - loss: 2617.5095\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f867eacbf28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx2Y8_FbPc0W",
        "colab_type": "code",
        "outputId": "4a4d851c-3d4a-4649-fa43-572c78e2ca21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_lstm_micr = Sequential()\n",
        "model_lstm_micr.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps_lstm, n_features_lstm)))\n",
        "model_lstm_micr.add(LSTM(50, activation='relu'))\n",
        "model_lstm_micr.add(Dense(1))\n",
        "model_lstm_micr.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "model_lstm_micr.fit(LSTM_X_micr, LSTM_y_micr, epochs=30, verbose=1)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "275/275 [==============================] - 1s 2ms/step - loss: 1673885.9345\n",
            "Epoch 2/30\n",
            "275/275 [==============================] - 0s 225us/step - loss: 1671558.7100\n",
            "Epoch 3/30\n",
            "275/275 [==============================] - 0s 227us/step - loss: 1663022.2364\n",
            "Epoch 4/30\n",
            "275/275 [==============================] - 0s 232us/step - loss: 1626515.8068\n",
            "Epoch 5/30\n",
            "275/275 [==============================] - 0s 260us/step - loss: 1496828.6950\n",
            "Epoch 6/30\n",
            "275/275 [==============================] - 0s 278us/step - loss: 1447157.4364\n",
            "Epoch 7/30\n",
            "275/275 [==============================] - 0s 230us/step - loss: 1410394.6150\n",
            "Epoch 8/30\n",
            "275/275 [==============================] - 0s 228us/step - loss: 1392839.5041\n",
            "Epoch 9/30\n",
            "275/275 [==============================] - 0s 262us/step - loss: 1369172.3968\n",
            "Epoch 10/30\n",
            "275/275 [==============================] - 0s 303us/step - loss: 1322857.6523\n",
            "Epoch 11/30\n",
            "275/275 [==============================] - 0s 292us/step - loss: 1255722.8064\n",
            "Epoch 12/30\n",
            "275/275 [==============================] - 0s 285us/step - loss: 1136451.4316\n",
            "Epoch 13/30\n",
            "275/275 [==============================] - 0s 284us/step - loss: 921435.5141\n",
            "Epoch 14/30\n",
            "275/275 [==============================] - 0s 317us/step - loss: 524671.5076\n",
            "Epoch 15/30\n",
            "275/275 [==============================] - 0s 327us/step - loss: 136857.7345\n",
            "Epoch 16/30\n",
            "275/275 [==============================] - 0s 297us/step - loss: 96993.3628\n",
            "Epoch 17/30\n",
            "275/275 [==============================] - 0s 298us/step - loss: 88083.8487\n",
            "Epoch 18/30\n",
            "275/275 [==============================] - 0s 283us/step - loss: 93674.5813\n",
            "Epoch 19/30\n",
            "275/275 [==============================] - 0s 281us/step - loss: 88713.3864\n",
            "Epoch 20/30\n",
            "275/275 [==============================] - 0s 235us/step - loss: 84765.4219\n",
            "Epoch 21/30\n",
            "275/275 [==============================] - 0s 254us/step - loss: 85523.4323\n",
            "Epoch 22/30\n",
            "275/275 [==============================] - 0s 248us/step - loss: 85462.2275\n",
            "Epoch 23/30\n",
            "275/275 [==============================] - 0s 227us/step - loss: 84192.8507\n",
            "Epoch 24/30\n",
            "275/275 [==============================] - 0s 243us/step - loss: 85050.1043\n",
            "Epoch 25/30\n",
            "275/275 [==============================] - 0s 242us/step - loss: 85161.3125\n",
            "Epoch 26/30\n",
            "275/275 [==============================] - 0s 245us/step - loss: 85454.0700\n",
            "Epoch 27/30\n",
            "275/275 [==============================] - 0s 271us/step - loss: 85198.0206\n",
            "Epoch 28/30\n",
            "275/275 [==============================] - 0s 246us/step - loss: 84504.9564\n",
            "Epoch 29/30\n",
            "275/275 [==============================] - 0s 230us/step - loss: 84171.0525\n",
            "Epoch 30/30\n",
            "275/275 [==============================] - 0s 235us/step - loss: 85336.8726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f867e641748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmJiiCqPbu6u",
        "colab_type": "code",
        "outputId": "8c7c942f-914c-484a-ecb8-3d92f3ff8a36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_lstm_refg = Sequential()\n",
        "model_lstm_refg.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps_lstm, n_features_lstm)))\n",
        "model_lstm_refg.add(LSTM(50, activation='relu'))\n",
        "model_lstm_refg.add(Dense(1))\n",
        "model_lstm_refg.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "\n",
        "\n",
        "model_lstm_refg.fit(LSTM_X_refg, LSTM_y_refg, epochs=30, verbose=1)\n",
        "\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "4485/4485 [==============================] - 2s 350us/step - loss: 18809.0217\n",
            "Epoch 2/30\n",
            "4485/4485 [==============================] - 1s 210us/step - loss: 1485.7068\n",
            "Epoch 3/30\n",
            "4485/4485 [==============================] - 1s 210us/step - loss: 1462.6039\n",
            "Epoch 4/30\n",
            "4485/4485 [==============================] - 1s 226us/step - loss: 1451.3930\n",
            "Epoch 5/30\n",
            "4485/4485 [==============================] - 1s 211us/step - loss: 1482.3535\n",
            "Epoch 6/30\n",
            "4485/4485 [==============================] - 1s 222us/step - loss: 1457.6663\n",
            "Epoch 7/30\n",
            "4485/4485 [==============================] - 1s 212us/step - loss: 1461.1083\n",
            "Epoch 8/30\n",
            "4485/4485 [==============================] - 1s 239us/step - loss: 1452.6032\n",
            "Epoch 9/30\n",
            "4485/4485 [==============================] - 1s 228us/step - loss: 1471.2911\n",
            "Epoch 10/30\n",
            "4485/4485 [==============================] - 1s 229us/step - loss: 1457.6867\n",
            "Epoch 11/30\n",
            "4485/4485 [==============================] - 1s 213us/step - loss: 1446.9150\n",
            "Epoch 12/30\n",
            "4485/4485 [==============================] - 1s 221us/step - loss: 1446.7921\n",
            "Epoch 13/30\n",
            "4485/4485 [==============================] - 1s 220us/step - loss: 1447.2340\n",
            "Epoch 14/30\n",
            "4485/4485 [==============================] - 1s 213us/step - loss: 1445.0655\n",
            "Epoch 15/30\n",
            "4485/4485 [==============================] - 1s 228us/step - loss: 1505.4717\n",
            "Epoch 16/30\n",
            "4485/4485 [==============================] - 1s 214us/step - loss: 1463.8627\n",
            "Epoch 17/30\n",
            "4485/4485 [==============================] - 1s 213us/step - loss: 1464.3301\n",
            "Epoch 18/30\n",
            "4485/4485 [==============================] - 1s 241us/step - loss: 1449.9541\n",
            "Epoch 19/30\n",
            "4485/4485 [==============================] - 1s 228us/step - loss: 1462.5290\n",
            "Epoch 20/30\n",
            "4485/4485 [==============================] - 1s 208us/step - loss: 1450.5066\n",
            "Epoch 21/30\n",
            "4485/4485 [==============================] - 1s 218us/step - loss: 1442.0032\n",
            "Epoch 22/30\n",
            "4485/4485 [==============================] - 1s 214us/step - loss: 1440.0856\n",
            "Epoch 23/30\n",
            "4485/4485 [==============================] - 1s 224us/step - loss: 1440.0959\n",
            "Epoch 24/30\n",
            "4485/4485 [==============================] - 1s 238us/step - loss: 1444.7363\n",
            "Epoch 25/30\n",
            "4485/4485 [==============================] - 1s 224us/step - loss: 1443.0949\n",
            "Epoch 26/30\n",
            "4485/4485 [==============================] - 1s 224us/step - loss: 1437.8760\n",
            "Epoch 27/30\n",
            "4485/4485 [==============================] - 1s 217us/step - loss: 1472.8031\n",
            "Epoch 28/30\n",
            "4485/4485 [==============================] - 1s 235us/step - loss: 1444.3927\n",
            "Epoch 29/30\n",
            "4485/4485 [==============================] - 1s 238us/step - loss: 1443.5526\n",
            "Epoch 30/30\n",
            "4485/4485 [==============================] - 1s 227us/step - loss: 1488.0815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f867e236f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4GWzmyhthE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CNN_pre_processing_test (dataset, appliance, starting, ending, value1, value2):\n",
        "  for i in range(starting, ending):\n",
        "    if value1 == 0:\n",
        "      if dataset[appliance][i] > value2:\n",
        "        dataset[\"Lite\"][i] = 1\n",
        "      else:\n",
        "        dataset[\"Lite\"][i] = 0\n",
        "\n",
        "    else:\n",
        "      if dataset[appliance][i] > value1:\n",
        "        if dataset[appliance][i] < value2:\n",
        "          dataset[\"Lite\"][i] = 1\n",
        "        else:\n",
        "          dataset[\"Lite\"][i] = 0\n",
        "      else:\n",
        "        dataset[\"Lite\"][i] = 0\n",
        "\n",
        "  x = dataset.values #returns a numpy array\n",
        "  min_max_scaler = preprocessing.MinMaxScaler()\n",
        "  x_scaled = min_max_scaler.fit_transform(x)\n",
        "  dataset1 = pd.DataFrame(x_scaled)\n",
        "\n",
        "\n",
        "  lite = (dataset.index[starting+1] - dataset.index[starting])\n",
        "  lite = str(lite)\n",
        "  main_array = []\n",
        "  check = lite\n",
        "\n",
        "  temp = []\n",
        "  for i in range(starting+1,ending):\n",
        "      difference = dataset.index[i] - dataset.index[i-1]\n",
        "      string = str(difference)\n",
        "      if string == check:\n",
        "          temp1 = []\n",
        "          temp2 = []\n",
        "          temp1.append(dataset1[0][i])\n",
        "          temp1.append(dataset[\"Lite\"][i])\n",
        "          temp.append(temp1)\n",
        "      else:\n",
        "          main_array.append(temp)\n",
        "          temp = []\n",
        "\n",
        "\n",
        "\n",
        "  final_array = []\n",
        "  for i in range(0,len(main_array)):\n",
        "      length = len(main_array[i])\n",
        "      modu = length%20\n",
        "      if modu < 10:\n",
        "          temp = []\n",
        "          for j in range(0,len(main_array[i])-modu):\n",
        "              temp.append(main_array[i][j])\n",
        "          final_array.append(temp)\n",
        "      else:\n",
        "          temp = main_array[i]\n",
        "          for j in range(0,20 - modu):\n",
        "              array = [0,0]\n",
        "              temp.append(array)\n",
        "          final_array.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "  test_array = []\n",
        "  for i in range(0,len(final_array)):\n",
        "      temp = []\n",
        "      for j in range(0,10):\n",
        "          temp.append([0,0])\n",
        "      for j in range(0,len(final_array[i])):\n",
        "          temp.append(final_array[i][j])\n",
        "      for j in range(0,10):\n",
        "          temp.append([0,0])\n",
        "      test_array.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "  training_set = []\n",
        "  for i in range(0,len(test_array)):\n",
        "      for j in range(0,len(test_array[i])-20):\n",
        "          x_y = []\n",
        "          temp = []\n",
        "          for k in range(j,j+20):\n",
        "              temp.append(test_array[i][k][0])\n",
        "          x_y.append(temp)\n",
        "          x_y.append(test_array[i][j+10][1])\n",
        "          training_set.append(x_y)\n",
        "\n",
        "\n",
        "  X = []\n",
        "  y = []\n",
        "  for i in range(0,len(training_set)):\n",
        "    lets = training_set[i][0]\n",
        "    lets = np.asarray(lets)\n",
        "    X.append(lets)\n",
        "    y.append(training_set[i][1])\n",
        "\n",
        "\n",
        "  X = np.asarray(X)\n",
        "  y = np.asarray(y)\n",
        "  from keras.utils import to_categorical\n",
        "  y = to_categorical(y)\n",
        "\n",
        "\n",
        "\n",
        "  return X,y;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kHXmrX9wSBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CNN_pre_processing_finaly (dataset, appliance, starting, ending, value1, value2):\n",
        "  for i in range(starting, ending):\n",
        "    if value1 == 0:\n",
        "      if dataset[appliance][i] > value2:\n",
        "        dataset[\"Lite\"][i] = 1\n",
        "      else:\n",
        "        dataset[\"Lite\"][i] = 0\n",
        "\n",
        "    else:\n",
        "      if dataset[appliance][i] > value1:\n",
        "        if dataset[appliance][i] < value2:\n",
        "          dataset[\"Lite\"][i] = 1\n",
        "        else:\n",
        "          dataset[\"Lite\"][i] = 0\n",
        "      else:\n",
        "        dataset[\"Lite\"][i] = 0\n",
        "\n",
        "  lite = (dataset.index[starting+1] - dataset.index[starting])\n",
        "  lite = str(lite)\n",
        "  main_array = []\n",
        "  check = lite\n",
        "\n",
        "  temp = []\n",
        "  for i in range(starting+1,ending):\n",
        "      difference = dataset.index[i] - dataset.index[i-1]\n",
        "      string = str(difference)\n",
        "      if string == check:\n",
        "          temp1 = []\n",
        "          temp2 = []\n",
        "          temp1.append(dataset[appliance][i])\n",
        "          temp1.append(dataset[\"Lite\"][i])\n",
        "          temp.append(temp1)\n",
        "      else:\n",
        "          main_array.append(temp)\n",
        "          temp = []\n",
        "\n",
        "\n",
        "\n",
        "  final_array = []\n",
        "  for i in range(0,len(main_array)):\n",
        "      length = len(main_array[i])\n",
        "      modu = length%20\n",
        "      if modu < 10:\n",
        "          temp = []\n",
        "          for j in range(0,len(main_array[i])-modu):\n",
        "              temp.append(main_array[i][j])\n",
        "          final_array.append(temp)\n",
        "      else:\n",
        "          temp = main_array[i]\n",
        "          for j in range(0,20 - modu):\n",
        "              array = [0,0]\n",
        "              temp.append(array)\n",
        "          final_array.append(temp)\n",
        "\n",
        "\n",
        "  final_y = []\n",
        "  for i in range(0,len(final_array)):\n",
        "    for j in range(0,len(final_array[i])):\n",
        "      final_y.append(final_array[i][j][0])\n",
        "  len(final_y)\n",
        "\n",
        "  return final_y;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_bQgAPpVRIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_refg, y_test_refg = CNN_pre_processing_test(dataset, \"Refg\", (len(dataset.index)-8000), len(dataset.index), 0, 100)\n",
        "\n",
        "X_test_micr, y_test_micr = CNN_pre_processing_test(dataset, \"Micr\", (len(dataset.index)-8000), len(dataset.index), 0, 600)\n",
        "\n",
        "X_test_dish1, y_test_dish1 = CNN_pre_processing_test(dataset, \"Dish\", (len(dataset.index)-8000), len(dataset.index), 100, 500)\n",
        "\n",
        "X_test_dish2, y_test_dish2 = CNN_pre_processing_test(dataset, \"Dish\", (len(dataset.index)-8000), len(dataset.index), 0, 850)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5Gb6br5xD_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_y = CNN_pre_processing_finaly(dataset, \"Refg\",  (len(dataset.index)-8000), len(dataset.index), 0, 100)\n",
        "\n",
        "final_y_micr = CNN_pre_processing_finaly(dataset, \"Micr\", (len(dataset.index)-8000), len(dataset.index), 0, 600)\n",
        "\n",
        "final_y_dish1 = CNN_pre_processing_finaly(dataset, \"Dish\", (len(dataset.index)-8000), len(dataset.index), 100, 500)\n",
        "\n",
        "final_y_dish2 = CNN_pre_processing_finaly(dataset, \"Dish\", (len(dataset.index)-8000), len(dataset.index), 0, 850)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnjH1OQ6tz60",
        "colab_type": "code",
        "outputId": "ee47cd74-7e21-404f-a189-696c7937c72c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(len(X_test_refg), len(y_test_refg), len(final_y))\n",
        "print(len(X_test_micr), len(y_test_micr), len(final_y_micr))\n",
        "print(len(X_test_dish1), len(y_test_dish1), len(final_y_dish1))\n",
        "print(len(X_test_dish2), len(y_test_dish2), len(final_y_dish2))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7980 7980 7980\n",
            "7980 7980 7980\n",
            "7980 7980 7980\n",
            "7980 7980 7980\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXHfSTuiR0b2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGhwXpWusHUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def testset_lstm (lite, deadload):\n",
        "  qwerty = []\n",
        "  flag = 0\n",
        "  for i in range(0,len(lite)):\n",
        "    if lite[i] == 0:\n",
        "      qwerty.append([deadload])\n",
        "      flag = 0\n",
        "      temp = [0,0,0,0,0]\n",
        "    else:\n",
        "      flag+=1\n",
        "      temp2 = []\n",
        "      qwerty.append(temp)\n",
        "      temp.append(flag)\n",
        "      for j in range(len(temp)-5,len(temp)):\n",
        "        temp2.append(temp[j])\n",
        "      temp = temp2\n",
        "  \n",
        "  for i in range(0,len(qwerty)):\n",
        "    if len(qwerty) > 2:\n",
        "      good = []\n",
        "      for j in range(0,len(qwerty[i])-1):\n",
        "        good.append(qwerty[i][j])\n",
        "      qwerty[i] = good\n",
        "    else:\n",
        "      qwerty[i] = qwerty[i].append(deadload)\n",
        "\n",
        "\n",
        "  final = []\n",
        "  for i in range(0,len(qwerty)):\n",
        "    if len(qwerty[i]) > 2:\n",
        "      good = []\n",
        "      for j in range(0,len(qwerty[i])):\n",
        "        good.append(qwerty[i][j])\n",
        "      final.append(good)\n",
        "    else:\n",
        "      temp = []\n",
        "      temp.append(deadload)\n",
        "      final.append(temp)\n",
        "\n",
        "  return final;\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fYx_C4NTzu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lite_refg = []\n",
        "for i in range(0,len(X_test_refg)):\n",
        "  x_input = X_test_refg[i].reshape(1,20,1)\n",
        "  yhat = model_refg.predict_classes(x_input,verbose=0)\n",
        "  lite_refg.append(yhat[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V9IK__VOZ2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lite_micr = []\n",
        "for i in range(0,len(X_test_micr)):\n",
        "  x_input = X_test_micr[i].reshape(1,20,1)\n",
        "  yhat = model_micr.predict_classes(x_input,verbose=0)\n",
        "  lite_micr.append(yhat[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r73b21hcfjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lite_dish1 = []\n",
        "for i in range(0,len(X_test_dish1)):\n",
        "  x_input = X_test_dish1[i].reshape(1,20,1)\n",
        "  yhat = model_dish1.predict_classes(x_input,verbose=0)\n",
        "  lite_dish1.append(yhat[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEHOavYgcfPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lite_dish2 = []\n",
        "for i in range(0,len(X_test_dish2)):\n",
        "  x_input = X_test_dish2[i].reshape(1,20,1)\n",
        "  yhat = model_dish2.predict_classes(x_input,verbose=0)\n",
        "  lite_dish2.append(yhat[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-E5fyqAuvj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Refg = testset_lstm(lite_refg, 7.5)\n",
        "Micr = testset_lstm(lite_micr, 4)\n",
        "Dish1 = testset_lstm(lite_dish1, 0)\n",
        "Dish2 = testset_lstm(lite_dish2, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA76Q4bhTziD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXwWHXO-TzKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lol = 0\n",
        "error = 0\n",
        "total = 0\n",
        "tot = 0\n",
        "tot_m = 0\n",
        "total_m = 0\n",
        "tot_d = 0\n",
        "total_d = 0\n",
        "\n",
        "for i in range(0,len(Refg)):\n",
        "  if len(Refg[i]) < 2:\n",
        "    predic = Refg[i][0]\n",
        "  else:\n",
        "    x_input = np.asarray(Refg[i])\n",
        "    x_input = x_input.reshape((1,5,1))\n",
        "    yhat = model_lstm_refg.predict(x_input, verbose=0)\n",
        "    predic = yhat[0][0]\n",
        "  #print(predic, final_y[i])\n",
        "  tot += predic\n",
        "  total += final_y[i]\n",
        "  #lol = (abs(predic+0.1 - final_y[i]+0.1)/ (final_y[i]+0.1))/7980\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,len(Micr)):\n",
        "  if len(Micr[i]) < 2:\n",
        "    predic = Micr[i][0]\n",
        "  else:\n",
        "    x_input = np.asarray(Micr[i])\n",
        "    x_input = x_input.reshape((1,5,1))\n",
        "    yhat = model_lstm_micr.predict(x_input, verbose=0)\n",
        "    predic = yhat[0][0]\n",
        "  #print(predic, final_y_micr[i])\n",
        "  tot_m += predic\n",
        "  total_m += final_y_micr[i]\n",
        "  #lol = (abs(predic+0.1 - final_y[i]+0.1)/ (final_y[i]+0.1))/7980\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(0,len(Dish2)):\n",
        "\n",
        "  if len(Dish2[i]) < 2:\n",
        "    if len(Dish1[i]) < 2:\n",
        "      predic = Dish2[i][0]\n",
        "    else:\n",
        "      x_input = np.asarray(Dish1[i])\n",
        "      x_input = x_input.reshape((1,5,1))\n",
        "      yhat = model_lstm_dish1.predict(x_input, verbose=0)\n",
        "      predic = yhat[0][0]\n",
        "  else:\n",
        "    x_input = np.asarray(Dish2[i])\n",
        "    x_input = x_input.reshape((1,5,1))\n",
        "    yhat = model_lstm_dish2.predict(x_input, verbose=0)\n",
        "    predic = yhat[0][0]\n",
        "\n",
        "  tot_d += predic\n",
        "  total_d += final_y_dish2[i]\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVzDpFV2Ty9p",
        "colab_type": "code",
        "outputId": "2374a043-67e9-4077-a463-bca2bff3afef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(tot, total)\n",
        "print(tot_m, total_m)\n",
        "print(tot_d, total_d)\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "446497.73806762695 462011.2909343933\n",
            "139598.81091308594 129298.89045545923\n",
            "178623.67350769043 205209.59031777052\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLIdaeMkTyh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "erro = abs((total + total_m + total_d) - (tot + tot_m + tot_d))/(total + total_m + total_d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mahKRhDeHIxp",
        "colab_type": "code",
        "outputId": "3258c66c-1e5d-42e9-f622-5b732c88cd51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "((1 - (abs(tot_d - total_d)/ total_d)) + (1 - (abs(tot_m - total_m)/ total_m)) + (1 - (abs(tot - total)/ total)))/3"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.919068994733307"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-Qz18rwH_lS",
        "colab_type": "code",
        "outputId": "2486bee9-5283-449c-9562-223b775e3dc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(1-erro)*100"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96.00768865397453"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fWrpe6zIA1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0Ot_QkcID7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGFId0c1IIlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tPRzxIZIcDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4865yZdcKU81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vng99xUJKdwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLAps81lKntK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdimIqNDLMW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEp6-7iULOcU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}